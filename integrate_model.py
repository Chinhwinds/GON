import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import json
from typing import List, Dict, Optional
import os

class EnvironmentalStoryGenerator:
    """Class ƒë·ªÉ t·∫°o c√¢u chuy·ªán m√¥i tr∆∞·ªùng s·ª≠ d·ª•ng fine-tuned Mistral model"""
    
    def __init__(self, model_path: str = "./mistral-environmental-stories"):
        """
        Kh·ªüi t·∫°o story generator
        
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn fine-tuned model
        """
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
    def load_model(self):
        """Load fine-tuned model v√† tokenizer"""
        try:
            print(f"ü§ñ Loading model from {self.model_path}...")
            
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_path,
                torch_dtype=torch.float16,
                device_map="auto" if self.device == "cuda" else None
            )
            
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            
            if self.device == "cpu":
                self.model = self.model.to(self.device)
            
            print("‚úÖ Model loaded successfully!")
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading model: {e}")
            return False
    
    def generate_single_story(self, card_info: str, temperature: float = 0.7) -> str:
        """
        T·∫°o c√¢u chuy·ªán t·ª´ th√¥ng tin m·ªôt th·∫ª
        
        Args:
            card_info: Th√¥ng tin th·∫ª (t√™n, lo·∫°i, hi·ªáu ·ª©ng)
            temperature: ƒê·ªô s√°ng t·∫°o c·ªßa model (0.0-1.0)
            
        Returns:
            C√¢u chuy·ªán ƒë∆∞·ª£c t·∫°o
        """
        if self.model is None or self.tokenizer is None:
            return "Model ch∆∞a ƒë∆∞·ª£c load. Vui l√≤ng g·ªçi load_model() tr∆∞·ªõc."
        
        try:
            # T·∫°o prompt
            system_prompt = "B·∫°n l√† m·ªôt AI chuy√™n t·∫°o c√¢u chuy·ªán v·ªÅ b·∫£o v·ªá m√¥i tr∆∞·ªùng d·ª±a tr√™n th·∫ª b√†i. H√£y t·∫°o c√¢u chuy·ªán ng·∫Øn g·ªçn, sinh ƒë·ªông v√† c√≥ √Ω nghƒ©a gi√°o d·ª•c v·ªÅ m√¥i tr∆∞·ªùng."
            
            prompt = f"<|system|>\n{system_prompt}\n<|end|>\n<|user|>\n{card_info}\n<|end|>\n<|assistant|>\n"
            
            # Tokenize
            inputs = self.tokenizer(prompt, return_tensors="pt")
            if self.device == "cuda":
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # Generate
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=100,
                    temperature=temperature,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )
            
            # Decode response
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            story = response.split("<|assistant|>\n")[-1].strip()
            
            return story
            
        except Exception as e:
            print(f"‚ùå Error generating story: {e}")
            return f"L·ªói khi t·∫°o c√¢u chuy·ªán: {e}"
    
    def generate_sequence_story(self, card_sequence: List[str], story_type: str = "adventure", 
                               length: str = "medium", temperature: float = 0.7) -> Dict:
        """
        T·∫°o c√¢u chuy·ªán t·ª´ chu·ªói th·∫ª b√†i
        
        Args:
            card_sequence: Danh s√°ch th√¥ng tin th·∫ª theo th·ª© t·ª±
            story_type: Lo·∫°i c√¢u chuy·ªán (adventure, educational, heroic)
            length: ƒê·ªô d√†i (short, medium, long)
            temperature: ƒê·ªô s√°ng t·∫°o
            
        Returns:
            Dict ch·ª©a title, content, moral
        """
        if not card_sequence:
            return {
                "title": "Kh√¥ng c√≥ th·∫ª n√†o ƒë∆∞·ª£c ch·ªçn",
                "content": "Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt th·∫ª ƒë·ªÉ t·∫°o c√¢u chuy·ªán.",
                "moral": "H√£y b·∫Øt ƒë·∫ßu v·ªõi nh·ªØng h√†nh ƒë·ªông nh·ªè ƒë·ªÉ b·∫£o v·ªá m√¥i tr∆∞·ªùng."
            }
        
        try:
            # T·∫°o prompt cho chu·ªói th·∫ª
            card_info = " | ".join(card_sequence)
            
            # Th√™m context v·ªÅ lo·∫°i c√¢u chuy·ªán
            story_context = {
                "adventure": "T·∫°o c√¢u chuy·ªán phi√™u l∆∞u v·ªÅ h√†nh tr√¨nh b·∫£o v·ªá m√¥i tr∆∞·ªùng",
                "educational": "T·∫°o c√¢u chuy·ªán gi√°o d·ª•c v·ªÅ b√†i h·ªçc b·∫£o v·ªá m√¥i tr∆∞·ªùng", 
                "heroic": "T·∫°o c√¢u chuy·ªán anh h√πng v·ªÅ cu·ªôc chi·∫øn b·∫£o v·ªá thi√™n nhi√™n"
            }
            
            length_context = {
                "short": "Ng·∫Øn g·ªçn (1-2 c√¢u)",
                "medium": "Chi ti·∫øt v·ª´a ph·∫£i (2-3 c√¢u)",
                "long": "Chi ti·∫øt ƒë·∫ßy ƒë·ªß (3-4 c√¢u)"
            }
            
            enhanced_prompt = f"{card_info}\n\nLo·∫°i c√¢u chuy·ªán: {story_context.get(story_type, '')}\nƒê·ªô d√†i: {length_context.get(length, '')}"
            
            # Generate story
            story_content = self.generate_single_story(enhanced_prompt, temperature)
            
            # Generate title v√† moral
            title = self._generate_title(story_type, length)
            moral = self._generate_moral()
            
            return {
                "title": title,
                "content": story_content,
                "moral": moral,
                "cardSequence": card_sequence
            }
            
        except Exception as e:
            print(f"‚ùå Error generating sequence story: {e}")
            return {
                "title": "L·ªói khi t·∫°o c√¢u chuy·ªán",
                "content": f"C√≥ l·ªói x·∫£y ra: {e}",
                "moral": "H√£y th·ª≠ l·∫°i sau.",
                "cardSequence": card_sequence
            }
    
    def _generate_title(self, story_type: str, length: str) -> str:
        """T·∫°o ti√™u ƒë·ªÅ c√¢u chuy·ªán"""
        titles = {
            "adventure": {
                "short": "Cu·ªôc Phi√™u L∆∞u Xanh Nh·ªè",
                "medium": "H√†nh Tr√¨nh B·∫£o V·ªá L√†ng Xanh", 
                "long": "S·ª© M·ªánh C·ª©u L·∫•y Th√†nh Ph·ªë Xanh"
            },
            "educational": {
                "short": "B√†i H·ªçc M√¥i Tr∆∞·ªùng ƒê·∫ßu Ti√™n",
                "medium": "Ch∆∞∆°ng Tr√¨nh Gi√°o D·ª•c Xanh",
                "long": "D·ª± √Ån Th·∫ø H·ªá Xanh To√†n Qu·ªëc"
            },
            "heroic": {
                "short": "Nh·ªØng Anh H√πng Xanh Nh·ªè",
                "medium": "Cu·ªôc Chi·∫øn B·∫£o V·ªá M√¥i Tr∆∞·ªùng",
                "long": "S·ª© M·ªánh C·ª©u L·∫•y H√†nh Tinh Xanh"
            }
        }
        
        return titles.get(story_type, {}).get(length, "C√¢u Chuy·ªán B·∫£o V·ªá M√¥i Tr∆∞·ªùng")
    
    def _generate_moral(self) -> str:
        """T·∫°o b√†i h·ªçc ƒë·∫°o ƒë·ª©c"""
        morals = [
            "B·∫£o v·ªá m√¥i tr∆∞·ªùng l√† tr√°ch nhi·ªám c·ªßa m·ªói ng∆∞·ªùi ch√∫ng ta, b·∫Øt ƒë·∫ßu t·ª´ nh·ªØng h√†nh ƒë·ªông nh·ªè nh·∫•t.",
            "Nh·ªØng h√†nh ƒë·ªông nh·ªè c√≥ th·ªÉ t·∫°o ra thay ƒë·ªïi l·ªõn cho thi√™n nhi√™n v√† t∆∞∆°ng lai c·ªßa ch√∫ng ta.",
            "Thi√™n nhi√™n l√† ng√¥i nh√† chung, h√£y c√πng nhau b·∫£o v·ªá v√† g√¨n gi·ªØ cho th·∫ø h·ªá mai sau.",
            "M·ªói h√†nh ƒë·ªông b·∫£o v·ªá m√¥i tr∆∞·ªùng ƒë·ªÅu c√≥ √Ω nghƒ©a s√¢u s·∫Øc v√† t√°c ƒë·ªông l√¢u d√†i ƒë·∫øn cu·ªôc s·ªëng.",
            "T∆∞∆°ng lai xanh b·∫Øt ƒë·∫ßu t·ª´ nh·ªØng h√†nh ƒë·ªông h√¥m nay, m·ªói ng∆∞·ªùi ƒë·ªÅu c√≥ th·ªÉ tr·ªü th√†nh anh h√πng m√¥i tr∆∞·ªùng."
        ]
        
        import random
        return random.choice(morals)

# API Server cho React app
from flask import Flask, request, jsonify
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# Global story generator
story_generator = None

@app.route('/api/load-model', methods=['POST'])
def load_model():
    """API endpoint ƒë·ªÉ load model"""
    global story_generator
    
    try:
        data = request.get_json()
        model_path = data.get('model_path', './mistral-environmental-stories')
        
        story_generator = EnvironmentalStoryGenerator(model_path)
        success = story_generator.load_model()
        
        return jsonify({
            'success': success,
            'message': 'Model loaded successfully' if success else 'Failed to load model'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error: {str(e)}'
        }), 500

@app.route('/api/generate-story', methods=['POST'])
def generate_story():
    """API endpoint ƒë·ªÉ t·∫°o c√¢u chuy·ªán"""
    global story_generator
    
    if story_generator is None:
        return jsonify({
            'success': False,
            'message': 'Model not loaded. Please load model first.'
        }), 400
    
    try:
        data = request.get_json()
        card_sequence = data.get('card_sequence', [])
        story_type = data.get('story_type', 'adventure')
        length = data.get('length', 'medium')
        temperature = data.get('temperature', 0.7)
        
        result = story_generator.generate_sequence_story(
            card_sequence, story_type, length, temperature
        )
        
        return jsonify({
            'success': True,
            'story': result
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error generating story: {str(e)}'
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': story_generator is not None
    })

if __name__ == '__main__':
    print("üöÄ Starting Environmental Story Generator API Server...")
    print("üìñ Endpoints:")
    print("  POST /api/load-model - Load fine-tuned model")
    print("  POST /api/generate-story - Generate environmental story")
    print("  GET  /api/health - Health check")
    
    app.run(host='0.0.0.0', port=5000, debug=True) 
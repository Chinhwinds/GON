# Fine-tuning Mistral 7B cho GON Environmental Stories

## ğŸ¯ Má»¥c tiÃªu

Fine-tune mÃ´ hÃ¬nh Mistral 7B Ä‘á»ƒ táº¡o cÃ¢u chuyá»‡n mÃ´i trÆ°á»ng tá»± nhiÃªn vÃ  sinh Ä‘á»™ng tá»« tháº» bÃ i trong game GON.

## ğŸ“ Files Ä‘Ã£ táº¡o

- `fine_tuning_data.jsonl` - Dataset training (24 máº«u)
- `train_mistral.py` - Script training chÃ­nh
- `generate_fine_tuning_data.py` - Script táº¡o dataset
- `integrate_model.py` - API server Ä‘á»ƒ tÃ­ch há»£p vá»›i React app
- `requirements_finetune.txt` - Dependencies cáº§n thiáº¿t
- `fine_tuning_guide.md` - HÆ°á»›ng dáº«n chi tiáº¿t

## ğŸš€ Quick Start

### 1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Táº¡o virtual environment
python -m venv mistral_env
source mistral_env/bin/activate  # Linux/Mac
# hoáº·c
mistral_env\Scripts\activate     # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements_finetune.txt
```

### 2. Cháº¡y Fine-tuning

```bash
# Cháº¡y training
python train_mistral.py

# Test model sau khi training
python train_mistral.py test
```

### 3. Cháº¡y API Server

```bash
# Khá»Ÿi Ä‘á»™ng API server
python integrate_model.py
```

## ğŸ“Š Dataset

Dataset hiá»‡n táº¡i cÃ³ 24 máº«u training:

- **8 tháº» Báº£o Vá»‡**: Trá»“ng rá»«ng, Ä‘áº­p ngÄƒn máº·n, phÃ¢n loáº¡i rÃ¡c,...
- **8 tháº» Cá»™ng Äá»“ng**: Sáº£n pháº©m xanh, tuyÃªn truyá»n, giáº£m nhá»±a,...
- **8 tháº» ThiÃªn Tai**: Sáº¡t lá»Ÿ, lÅ© quÃ©t, chÃ¡y rá»«ng,...

## ğŸ”§ Cáº¥u hÃ¬nh Training

- **Model**: Mistral 7B v0.1
- **Method**: LoRA (Low-Rank Adaptation)
- **Quantization**: 4-bit Ä‘á»ƒ tiáº¿t kiá»‡m VRAM
- **Epochs**: 3
- **Learning Rate**: 2e-4
- **Batch Size**: 4

## ğŸ’» YÃªu cáº§u há»‡ thá»‘ng

- **GPU**: 24GB+ VRAM (A100, V100, RTX 4090)
- **RAM**: 64GB+
- **Storage**: 100GB+ free space

## ğŸ”„ Integration vá»›i React App

### 1. Load Model

```javascript
const response = await fetch("/api/load-model", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({ model_path: "./mistral-environmental-stories" }),
});
```

### 2. Generate Story

```javascript
const response = await fetch("/api/generate-story", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    card_sequence: [
      "TÃªn tháº»: Trá»“ng Rá»«ng Äáº§u Nguá»“n. Loáº¡i: Báº£o Vá»‡. Hiá»‡u á»©ng: +2 Ä‘iá»ƒm cho Rá»«ng.",
    ],
    story_type: "adventure",
    length: "medium",
    temperature: 0.7,
  }),
});
```

## ğŸ“ˆ Káº¿t quáº£ mong Ä‘á»£i

Sau khi fine-tuning, model sáº½:

- âœ… Táº¡o cÃ¢u chuyá»‡n tá»± nhiÃªn tá»« thÃ´ng tin tháº» bÃ i
- âœ… Duy trÃ¬ phong cÃ¡ch ká»ƒ chuyá»‡n nháº¥t quÃ¡n
- âœ… TÃ­ch há»£p hiá»‡u á»©ng game mÆ°á»£t mÃ 
- âœ… Táº¡o ná»™i dung giÃ¡o dá»¥c cháº¥t lÆ°á»£ng cao

## ğŸ® Sá»­ dá»¥ng trong Game

1. NgÆ°á»i chÆ¡i chá»n tháº» bÃ i theo thá»© tá»±
2. Gá»­i thÃ´ng tin tháº» Ä‘áº¿n API
3. Nháº­n cÃ¢u chuyá»‡n mÃ´i trÆ°á»ng Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng
4. Hiá»ƒn thá»‹ cÃ¢u chuyá»‡n vá»›i giao diá»‡n Ä‘áº¹p

## ğŸ” Troubleshooting

### Lá»—i VRAM khÃ´ng Ä‘á»§

- Giáº£m batch size xuá»‘ng 2
- Sá»­ dá»¥ng gradient checkpointing
- TÄƒng gradient accumulation steps

### Lá»—i loading model

- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n model
- Äáº£m báº£o Ä‘Ã£ download Mistral 7B
- Kiá»ƒm tra quyá»n truy cáº­p file

### Lá»—i training

- Kiá»ƒm tra format dataset
- Äáº£m báº£o Ä‘á»§ disk space
- Kiá»ƒm tra GPU drivers

## ğŸ“ Há»— trá»£

Náº¿u gáº·p váº¥n Ä‘á», hÃ£y kiá»ƒm tra:

1. Logs trong console
2. GPU memory usage
3. Dataset format
4. Dependencies versions
